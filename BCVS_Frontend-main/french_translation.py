# -*- coding: utf-8 -*-
"""French Translation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12Ld-4o9Fdz0N095lsEYxO-Ia09NgC1Rn
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture 
# !pip install transformers datasets sentencepiece sacremoses

from oauth2client.service_account import ServiceAccountCredentials
import gspread
import re
import os
import torch
import numpy as np
import datasets
from datasets import load_dataset
import pandas as pd
import transformers
import spacy
from transformers import MarianMTModel, MarianTokenizer, AutoModelForSeq2SeqLM
nlp = spacy.load('en_core_web_sm')

def single_translate(
    text: str,
    model: transformers.models.marian.modeling_marian.MarianMTModel,
    tokenizer: transformers.models.marian.tokenization_marian.MarianTokenizer
):
  inputs = tokenizer(text, max_length=128, padding="max_length", truncation=True, return_tensors="pt")
  translated_ids = model.generate(**inputs.to(devices), max_length=128)
  return [tokenizer.decode(t, skip_special_tokens=True) for t in translated_ids][0]

def batch_translate(
    texts: pd.DataFrame,
    model: transformers.models.marian.modeling_marian.MarianMTModel,
    tokenizer: transformers.models.marian.tokenization_marian.MarianTokenizer    
):
  predictions = []
  df = pd.DataFrame({"text": texts})
  for _, row in df.iterrows():
    translated_ids = model.generate(**tokenizer(row["text"], return_tensors="pt", padding=True))
    predictions.extend([tokenizer.decode(t, skip_special_tokens=True) for t in translated_ids])
  return predictions

def check_for_batch(text: str, tokenizer: transformers.models.marian.tokenization_marian.MarianTokenizer, threshold: int = 128):
  token_length = len(tokenizer(text)["input_ids"])
  return True if token_length > threshold else False

class French_Translation:
  def __init__(
      self, 
      process_code: str, 
      text: str):
    self.process_code = process_code
    self.text = text

  def __repr__(self):
    return "Languages: English ('en') OR German ('de')"

  def __str__(self):
    return str(self.__repr__())
    
  def translate_2_english(self, model, tokenizer):
    is_batch = check_for_batch(self.text, tokenizer)
    if is_batch:
      print("document limit exceeded, applying segemented translation")
      doc = nlp(self.text)
      sentences = [sent.text.strip() for sent in doc.sents]
      translated_text = ". ".join([single_translate(text=sent, model=model, tokenizer=tokenizer) for sent in sentences])
    else:
      translated_text = single_translate(text=self.text, model=model, tokenizer=tokenizer)
    return translated_text

  def translate_2_german(self, model, tokenizer):
    is_batch = check_for_batch(self.text, tokenizer)
    if is_batch:
      print("document limit exceeded, applying segemented translation")
      doc = nlp(self.text)
      sentences = [sent.text.strip() for sent in doc.sents]
      translated_text = ". ".join([single_translate(text=sent, model=model, tokenizer=tokenizer) for sent in sentences])
    else:
      translated_text = single_translate(text=self.text, model=model, tokenizer=tokenizer)
    return translated_text

if __name__ == "__main__":
  model_checkpoints = {
      "en": "Helsinki-NLP/opus-mt-fr-en",
      "de": "Helsinki-NLP/opus-mt-fr-de"
  }
  devices = torch.device("cuda" if torch.cuda.is_available() else "cpu")
  # initialize french opus translation models and tokenizers
  fr_2_en_tokenizer = MarianTokenizer.from_pretrained(model_checkpoints["en"])
  fr_2_en_model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints["en"])
  fr_2_de_tokenizer = MarianTokenizer.from_pretrained(model_checkpoints["de"])
  fr_2_de_model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints["de"])
  
  process_code = "xgGd"

  text = """Ils sont une poignée, quatre hommes, assis sans trop se dire grand-chose au fond d’un des rares établissements encore ouverts de Kramatorsk. L’endroit n’est pas bien gai, avec sa tonnelle de tôle et ses chaises dépareillées où dort un vieux chat, mais il est ouvert et sert un peu d’alcool, chose désormais totalement interdite dans cette ville comme dans toute la partie du Donbass que contrôle l’Ukraine. Les vagues vêtements civils ne suffisent pas à cacher les pièces d’uniformes et les airs de soldats. Ils ont les traits tirés de fatigue. Lentement, debout, ils lèvent de petits verres de vodka, étonnamment délicats à la mémoire de leurs amis tombés au front. Deux. Passers-by walk along School No. 23 with its gutted facade, without really paying attention. In this peaceful area of ​​Kramatorsk , two Russian strikes reduced the three-story building to a pile of rubble. Municipal workers gathered the broken glass into small piles, a derisory attempt to reorganize this tangle of concrete and scrap metal. The night of the attack, the whole neighborhood was awakened by the detonations. Ivan, who heard everything from his bed, did not try to find out more. Because the curfew prevented it, but also by weariness of these repeated destructions. Back from the market, his shirt open to withstand the heat of this late morning, he is more interested in the rise in the price of the tomatoes and zucchini he is transporting on his bike. “ I am tired of this war. Ukrainians, Russians , everyone is tired of this war ,” the young man said. The attack made three…"""
  # text = "Je vais à une fête demain"
  
  # french translation object
  french_translation = French_Translation(process_code=process_code, text=text)
  print(french_translation.translate_2_english(model=fr_2_en_model, tokenizer=fr_2_en_tokenizer))
  print(french_translation.translate_2_german(model=fr_2_de_model, tokenizer=fr_2_de_tokenizer))

